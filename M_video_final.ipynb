{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('X_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Признаки\n",
    "\n",
    "Закодировали one-hot категориальные признаки и снизили размерность с помощью метода главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform = ['sku', 'categoryLevel1Id', 'categoryLevel2Id', 'brandId', 'userName']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full2 = pd.get_dummies(columns = cols_to_transform, data=df[cols_to_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_cat = PCA(n_components=1000)\n",
    "pca_cat = pca_cat.fit_transform(full2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты комментариев лемматизируем с помощью mystem3, посчитаем матрицу tf-idf и также снизим ее размерность с помощью метода главных компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_file = open('comments.txt', 'w')\n",
    "for text in df.comment.values:\n",
    "    output_file.write(text + '\\n')\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./mystem -cl comments.txt norm_comments2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('norm_comments.txt', 'r')\n",
    "prog = re.compile('{[А-Яа-я\\|]+}')\n",
    "norm_texts = []\n",
    "for line in f.readlines():\n",
    "    norm_texts.append([l[1:-1].split(\"|\") for l in prog.findall(line.lower())])\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_texts2 = [' '.join([word[0] for word in text]) for text in norm_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tiv = TfidfVectorizer()\n",
    "nwd = tiv.fit_transform(norm_texts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1000)\n",
    "pca_data = pca.fit_transform(nwd.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим еще несколько признаков:\n",
    "\n",
    "1. средняя тональность слов в комментарии (учитываются только те слова, у которых тональность в словаре ... не ноль)\n",
    "\n",
    "2. количество слов\n",
    "\n",
    "3. Веселые и грустные смайлики\n",
    "\n",
    "4. Количство предложений\n",
    "\n",
    "5. Количество восклицательных знаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = pd.read_csv('words.csv', sep=';', header=None, names =['word', 'sent', '1', '2', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Dict = sent.groupby('word')['sent'].mean().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tone = np.zeros((len(norm_texts), 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(norm_texts):\n",
    "    count = 0\n",
    "    for j, word in enumerate(text):\n",
    "        s = Dict.get(word[0], 0)\n",
    "        if s != 0:\n",
    "            count += 1\n",
    "            if j >= 1:\n",
    "                if text[j-1][0] == 'не':\n",
    "                    s = - s\n",
    "            tone[i, 0] += s\n",
    "    if count:\n",
    "        tone[i, 0] = tone[i, 0]/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(norm_texts):\n",
    "    tone[i, 1] = len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(df.comment):\n",
    "    left = 0\n",
    "    right = 0\n",
    "    for j, word in enumerate(text):\n",
    "        if word == ')':\n",
    "            right += 1\n",
    "        if word == '(':\n",
    "            left += 1\n",
    "    if (right - left)%2 == 1:\n",
    "        if right - left > 0:\n",
    "            tone[i, 2] = 1\n",
    "        else:\n",
    "            tone[i, 3] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(df.comment):\n",
    "    sents = sent_tokenize(text)\n",
    "    tone[i, 4] = len(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, text in enumerate(df.comment):\n",
    "    for e in text:\n",
    "        if e == '!':\n",
    "            tone[i, 5] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Целевая переменная\n",
    "\n",
    "Так как практически все оценки, целые задачу можно сформулировать как многоклассовую классификацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = list(map(int, np.round(df.reting)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение классификатора\n",
    "\n",
    "Разобьем выборку на обучающую и тестовую и обучим классификаторы с параметрами, подобранными на кросс-валидации. Обучим логистическую регрессию one vs rest с разрежеванием (l1 регуляризатор) и далее обучим логистическую регрессию с l2 регуляризатором и оценим качество на кросс-валидации и отложенной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = np.hstack((pca_cat, pca_data, tone))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = LogisticRegression(multi_class=\"ovr\", penalty='l1', C=1.1)\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (model1.coef_[0, :] == 0) & (model1.coef_[1, :] == 0) & (model1.coef_[2, :] == 0) & (model1.coef_[3, :] == 0) & (model1.coef_[4, :] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(multi_class=\"ovr\", penalty='l2', C=1.3) #0.89\n",
    "model2.fit(X_train[:, ~ind], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценим качество\n",
    "\n",
    "Так как выборка сильно смещена в сторону пяти (примерно половина отзывов имеют рейтинг пять), будем использовать микро усредненную f-меру для сравнения качества работы алгоритмов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_pr1 = model1.predict(X_train)\n",
    "y_test_pr1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pr2 = model2.predict(X_train[:, ~ind])\n",
    "y_test_pr2 = model2.predict(X_test[:, ~ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66132135984605511"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_test, y_pred=y_test_pr2, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74315654405474763"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_true=y_train, y_pred=y_train_pr2, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66125045521371228"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(multi_class=\"ovr\", penalty='l2', C=1.3)\n",
    "scores = cross_val_score(model, X_train[:, ~ind], y_train, cv=5, scoring='f1_micro')\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
